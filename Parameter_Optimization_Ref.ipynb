{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqBSQOJfF8Azu8yWMtDmGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muzammil-Elahi/Dividend-Policy-Predictor/blob/main/Parameter_Optimization_Ref.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj33cDRW8UtO"
      },
      "outputs": [],
      "source": [
        "# Bayesian Optimization\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Define the parameter search space\n",
        "search_spaces = {\n",
        "    'n_estimators': (10, 200),\n",
        "    'max_depth': (10, 50),\n",
        "    'min_samples_split': (2, 10)\n",
        "}\n",
        "\n",
        "# n_estimators=100: The number of trees in the forest.\n",
        "# criterion='gini': The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
        "# max_depth=None: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "# min_samples_split=2: The minimum number of samples required to split an internal node.\n",
        "# min_samples_leaf=1: The minimum number of samples required to be at a leaf node.\n",
        "# max_features='auto': The number of features to consider when looking for the best split.\n",
        "# bootstrap=True: Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
        "# random_state=None: Controls the randomness of the estimator.\n",
        "\n",
        "\n",
        "# Initialize BayesSearchCV\n",
        "bayes_search = BayesSearchCV(estimator=model, search_spaces=search_spaces, n_iter=32, cv=5, scoring='accuracy', random_state=42)\n",
        "\n",
        "# Fit the Bayesian search\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = bayes_search.best_params_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)"
      ]
    }
  ]
}